{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed54dc3d",
   "metadata": {},
   "source": [
    "# Setup\n",
    "## Colab: Install packages (must restart runtime after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6e719b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=1\n",
    "%env NCCL_P2P_DISABLE=1\n",
    "%env NCCL_IB_DISABLE=1\n",
    "\n",
    "GLOBALS = {\"colab\": \"google.colab\" in str(get_ipython())}\n",
    "\n",
    "if GLOBALS[\"colab\"]:\n",
    "    ! pip install transformers -q\n",
    "    ! pip install datasets accelerate peft -q\n",
    "    ! pip install accelerate -qU\n",
    "    ! pip install wandb -qU\n",
    "    # ! pip install pysentimiento -q\n",
    "\n",
    "    from google.colab import drive, userdata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2920c8",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a910586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "if GLOBALS[\"colab\"]:\n",
    "    drive.mount(\"/content/drive\")\n",
    "    # Clone repo\n",
    "    ! git clone https://github.com/Pastells/Human-vs.-Machine-Perceptions-on-Immigration-Stereotypes.git\n",
    "\n",
    "    # Create results and models folders in /content\n",
    "    ! mkdir -p results/metrics\n",
    "    ! mkdir -p results/trainer_logs\n",
    "    ! mkdir -p models/stereohoax\n",
    "\n",
    "    sys.path.append(\"/content/Human-vs.-Machine-Perceptions-on-Immigration-Stereotypes\")\n",
    "    os.environ[\"WANDB_API_KEY\"] = userdata.get(\"wandb\")\n",
    "else:\n",
    "    secret = pd.read_csv(\"secret.config\", header=None)\n",
    "    os.environ[\"WANDB_API_KEY\"] = secret[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21ed626",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.fine_tuning import main_loop\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.precision\", 3)\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:512\"\n",
    "os.environ[\"WANDB_LOG_MODEL\"] = \"false\"\n",
    "os.environ[\"WANDB_DISABLED\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d58ed3",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4d06a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "GLOBALS[\"experiment_name\"] = \"proves\"\n",
    "GLOBALS[\"max_tokens\"] = 128\n",
    "GLOBALS[\"device\"] = DEVICE\n",
    "# -----------------------------------\n",
    "# Technical variables, single values\n",
    "# -----------------------------------\n",
    "\n",
    "H_PARAMS = {\n",
    "    \"output_dir\": \"/content\" if GLOBALS[\"colab\"] else \".\",\n",
    "    \"save_models\": False,  # Save models to Drive\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\": 10,  # 20,\n",
    "    \"n_steps\": 50,\n",
    "    \"patience\": 8,  # times N_STEPS\n",
    "    \"class_weights\": None,\n",
    "    \"save\": 5,  # How many checkpoints to keep\n",
    "    \"lora\": False,  # LoRA if True, FFT otherwise\n",
    "    \"fp16\": False,\n",
    "}\n",
    "# H_PARAMS[\"n_steps\"] = H_PARAMS[\"n_steps\"] / H_PARAMS[\"batch_size\"] * 32\n",
    "\n",
    "# Layer-Wise Layer Rate Decay\n",
    "LLRD = {\n",
    "    \"LLRD\": False,  # {False, True, \"grouped\"}\n",
    "    \"lr_decay\": 0.9,  # if LLRD is True\n",
    "    \"C1\": 1.75,  # if LLRD == grouped\n",
    "    \"C2\": 3.5,  # if LLRD == grouped\n",
    "}\n",
    "\n",
    "DATA_PARAMS = {\n",
    "    \"append\": False,  # Append context instead of using [SEP] token\n",
    "    \"fill\": True,  # Fill missing contexts\n",
    "    \"cont_same_as_txt\": True,\n",
    "    \"fill_same\": True,\n",
    "    \"files\": None,  # Change if you want custom files (see cell below for few-shot)\n",
    "}\n",
    "\n",
    "# ------------------------------------\n",
    "# SETUP\n",
    "# If multiple values -> loop\n",
    "# ------------------------------------\n",
    "# Do not mix different data and context, each data has its own context\n",
    "SEEDS = (42,)\n",
    "DATA_SOFT = (\n",
    "    (\"stereohoax\", False),\n",
    "    (\"stereohoax\", True),\n",
    ")\n",
    "SEEDS_DATA_SOFT = itertools.product(SEEDS, DATA_SOFT)\n",
    "\n",
    "MODELS = {\n",
    "    # \"beto\": \"dccuchile/bert-base-spanish-wwm-cased\",\n",
    "    \"roberta_bne\": \"PlanTL-GOB-ES/roberta-base-bne\",\n",
    "    # \"roberta_large_bne\": \"PlanTL-GOB-ES/roberta-large-bne\",\n",
    "    # \"bertin\": \"bertin-project/bertin-roberta-base-spanish\",\n",
    "    # \"mbert\": \"google-bert/bert-base-multilingual-cased\",\n",
    "    # \"robertuito\": \"pysentimiento/robertuito-base-uncased\", # raises CUDA error for max_tokens > 128\n",
    "    # \"albeto\": \"dccuchile/albert-base-spanish\",\n",
    "    # \"beto_uncased\": \"dccuchile/bert-base-spanish-wwm-uncased\",\n",
    "}\n",
    "\n",
    "CONTEXTS = (None,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbd40f7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "# Models loop (main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ae8849",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_loop(SEEDS_DATA_SOFT, DATA_PARAMS, CONTEXTS, H_PARAMS, MODELS, GLOBALS, LLRD)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
